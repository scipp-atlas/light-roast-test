{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7cdbf-cf03-4f80-948c-1c2c7884306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this portion is done to ignore warnings from coffea for now\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import dask\n",
    "import dask_awkward as dak\n",
    "import parse\n",
    "from atlas_schema.methods import behavior as as_behavior\n",
    "from atlas_schema.schema import NtupleSchema\n",
    "from coffea import processor\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "from coffea.dataset_tools import apply_to_fileset\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue.htcondor import HTCondorCluster\n",
    "from dask.distributed import LocalCluster\n",
    "from matplotlib import pyplot as plt\n",
    "import hist.dask as had\n",
    "\n",
    "fname_pattern = parse.compile(\n",
    "    \"user.{username:w}.{dsid:d}.{process:S}.{campaign:w}.v{version:.1f}_ANALYSIS.root\"\n",
    ")\n",
    "\n",
    "colors_dict = {\n",
    "    \"Znunu\": \"b\",\n",
    "    \"Wenu\": \"g\",\n",
    "    \"Wmunu\": \"r\",\n",
    "    \"Wtaunu_L\": \"c\",\n",
    "    \"Wtaunu_H\": \"m\",\n",
    "    \"Znunugamma\": \"y\",\n",
    "    \"Wmunugamma\": \"k\",\n",
    "    \"Wenugamma\": \"brown\",\n",
    "    \"Wtaunugamma\": \"pink\",\n",
    "    \"N2_100_N1_97_WB_signal\": \"rosybrown\",\n",
    "    \"Fake/Nonprompt\": \"lime\",\n",
    "}  #  'slategrey', 'blueviolet', 'crimson'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab73c1-a262-459b-b2f7-d80859abf41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        \n",
    "        h_ph_pt = (\n",
    "            had.Hist.new.StrCat([\"A_true\",\"B_true\",\"C_true\",\"D_true\",\n",
    "                                 \"A_fake\",\"B_fake\",\"C_fake\",\"D_fake\"], name=\"ABCD\")\n",
    "            .Regular(100, 0.0, 100.0, name=\"pt\", label=\"$pt_{\\\\gamma}$ [GeV]\")\n",
    "            .Int64()\n",
    "        )\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def process(self, events):\n",
    "        ## TODO: remove this temporary fix when https://github.com/scikit-hep/vector/issues/498 is resolved\n",
    "        met_dict = {field: events.met[field] for field in events.met.fields}\n",
    "        met_dict[\"pt\"] = dak.zeros_like(events.met.met)\n",
    "        met_dict[\"eta\"] = dak.zeros_like(events.met.met)\n",
    "        events[\"met\"] = dak.zip(met_dict, with_name=\"MissingET\", behavior=as_behavior)\n",
    "\n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "        \n",
    "        print(f\"processing {len(events)} events for {dataset}\")\n",
    "        # xs = events.metadata[\"xs\"]\n",
    "        # lum = events.metadata[\"luminosity\"]\n",
    "        # process = events.metadata[\"process\"]\n",
    "        # genFiltEff = events.metadata[\"genFiltEff\"]\n",
    "        # evt_count = ak.num(events, axis=0).compute()\n",
    "        # weights = (xs * genFiltEff * lum / evt_count) * np.ones(evt_count)\n",
    "\n",
    "        leptons = ak.concatenate((events.el, events.mu), axis=1)\n",
    "\n",
    "        # here are some selection cuts for something that looks like the signal region.\n",
    "        # the only thing that's different is the MET requirement, which I inverted to be\n",
    "        # met<250 instead of met>250, to make sure we don't accidentally unblind the SR\n",
    "        # and to give us some more stats while we study MC samples.\n",
    "        selections = {\n",
    "            \"met\": events.met.met < 250 * 1.0e3,\n",
    "            \"lepton_veto\": ak.num(leptons, axis=1) == 0,\n",
    "            \"leading_jet_pt\": ak.firsts(events.jet.pt) > 100 * 1.0e3,\n",
    "            \"min_dphi_jet_met\": ak.min(events.met.delta_phi(events.jet), axis=1) > 0.4,\n",
    "            \"bjet_veto\": ak.sum(events.jet.btag_select, axis=1) == 0,\n",
    "            \"vgamma_overlap\": events[\"in\"][\n",
    "                \"vgamma_overlap_7\"\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        selection = PackedSelection()\n",
    "        selection.add_multiple(selections)\n",
    "\n",
    "        SR=(selection.all())\n",
    "\n",
    "        # photon object preselection\n",
    "        photon_preselection = ak.first(\n",
    "            (events.ph.pt>10000) &\n",
    "            (events.ph.select_baseline==1) &\n",
    "            ((events.ph.isEM&0x45fc01)==0) &\n",
    "            (\n",
    "             (abs(events.ph.eta)<1.37) | \n",
    "             ((abs(events.ph.eta)>1.52) & \n",
    "              (abs(events.ph.eta)<2.37))\n",
    "            ) &\n",
    "            (events.ph.select_or_dR02Ph==1)\n",
    "        )\n",
    "\n",
    "        ph_tight = (events.ph.select_tightID==1)\n",
    "        ph_iso   = (events.ph.select_tightIso==1)\n",
    "        ph_truth = ((events.ph.truthType != 0) & (events.ph.truthType != 16))\n",
    "\n",
    "        h_ph_pt.fill(ABCD=\"A_true\", pt=ak.firsts(events[SR & photon_preselection &  ph_tight & ~ph_iso &  ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"B_true\", pt=ak.firsts(events[SR & photon_preselection & ~ph_tight & ~ph_iso &  ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"C_true\", pt=ak.firsts(events[SR & photon_preselection &  ph_tight &  ph_iso &  ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"D_true\", pt=ak.firsts(events[SR & photon_preselection & ~ph_tight &  ph_iso &  ph_truth].ph.pt) / 1.0e3)\n",
    "\n",
    "        h_ph_pt.fill(ABCD=\"A_fake\", pt=ak.firsts(events[SR & photon_preselection &  ph_tight & ~ph_iso & ~ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"B_fake\", pt=ak.firsts(events[SR & photon_preselection & ~ph_tight & ~ph_iso & ~ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"C_fake\", pt=ak.firsts(events[SR & photon_preselection &  ph_tight &  ph_iso & ~ph_truth].ph.pt) / 1.0e3)\n",
    "        h_ph_pt.fill(ABCD=\"D_fake\", pt=ak.firsts(events[SR & photon_preselection & ~ph_tight &  ph_iso & ~ph_truth].ph.pt) / 1.0e3)\n",
    "\n",
    "        return {\n",
    "            dataset: {\n",
    "                \"entries\": ak.num(events, axis=0),\n",
    "                \"ph_pt\": h_ph_pt,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1f716-ab1b-4995-a39f-15b0f35b7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "my_processor = MyProcessor()\n",
    "\n",
    "# load in a bunch of datasets\n",
    "#dataset_runnable = json.loads(Path(\"af_v2.json\").read_text())\n",
    "dataset_runnable = json.loads(Path(\"af_v2_onefile.json\").read_text())\n",
    "\n",
    "cluster=None\n",
    "dataset_to_run=None\n",
    "\n",
    "can_submit_to_condor=False\n",
    "datasettag='Znunugamma'\n",
    "\n",
    "if can_submit_to_condor:\n",
    "    # To facilitate usage with HTCondor\n",
    "    cluster = HTCondorCluster(\n",
    "        log_directory=Path().cwd() / \".condor_logs\" / \"cutflows_v2\",\n",
    "        cores=4,\n",
    "        memory=\"4GB\",\n",
    "        disk=\"2GB\",\n",
    "    )\n",
    "    cluster.scale(jobs=100)\n",
    "\n",
    "    # if we're running over all samples, ensure that here\n",
    "    dataset_to_run=dataset_runnable\n",
    "else:\n",
    "    cluster=LocalCluster()\n",
    "    dataset_to_run={datasettag: dataset_runnable[datasettag]}\n",
    "\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "print(\"Applying to fileset\")\n",
    "out = apply_to_fileset(\n",
    "    my_processor,\n",
    "    dataset_to_run,\n",
    "    schemaclass=NtupleSchema,\n",
    ")\n",
    "\n",
    "print(\"Beginning of dask.compute()\")\n",
    "\n",
    "# Add progress bar for dask\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "(computed,) = dask.compute(out)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Execution time: \", end_time - start_time)\n",
    "print(\"Finished dask.compute\")\n",
    "print(computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40e148-7e26-4cd8-bce0-44094c78a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, ax = plt.subplots()\n",
    "computed[datasettag][datasettag][\"ph_pt\"].plot1d(ax=ax)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(title=\"Photon pT for $\\\\gamma + W\\\\rightarrow e \\\\nu$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f06e8d-cfad-4687-93f6-65f5a3b61a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62526d5f-10ad-4902-b2a8-b007b5f9b475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light-roast-kernel",
   "language": "python",
   "name": "light-roast-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
